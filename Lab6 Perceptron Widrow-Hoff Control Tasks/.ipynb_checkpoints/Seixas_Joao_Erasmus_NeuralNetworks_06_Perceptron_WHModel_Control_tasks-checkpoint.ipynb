{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erasmus Neural Networks\n",
    "http://michalbereta.pl/nn\n",
    "## Control tasks for Perceptron and Widrow-Hoff model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "Exacute the examples.\n",
    "\n",
    "Then, do the tasks and send back the notebook.\n",
    "\n",
    "Change the name of this notebook according to the schema: {YourSurname}\\_{YourFirstName}\\_{OriginalFileName}.\n",
    "\n",
    "Be sure to fill all places with \"YOUR ANSWER HERE\".\n",
    "\n",
    "When ready, send the notebook, with all the necessary files zipped, to the teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do\n",
    "\n",
    "- Fill the methods of the following classes with your implementation.\n",
    "\n",
    "- Read the comments to properly implement methods.\n",
    "\n",
    "- Avoid loops when possible. Use numpy operations on matrices and vectors, instead.\n",
    "\n",
    "- Execute the test code.\n",
    "\n",
    "- Compare the results with the expected results given.\n",
    "\n",
    "- Do not change the testing code, just the implementation od classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Online version of Perceptron learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "`\n",
    "Loading train data...\n",
    "Train data:\n",
    "Number of examples= 500\n",
    "Number of inputs= 10\n",
    "Initial number of errors= 225\n",
    "Training...\n",
    "End of training\n",
    "Errors for train data after training= 0\n",
    "Loading test data...\n",
    "Test data:\n",
    "Number of examples= 439\n",
    "Number of inputs= 10\n",
    "Calculating answers for test data...\n",
    "Saving classifications for test data...\n",
    "Checking test error...\n",
    "Test errors= 2  ->  0.004555808656036446 %\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 193\n",
      "Training...\n",
      "End of training\n",
      "Errors for train data after training= 0\n",
      "Loading test data...\n",
      "Test data:\n",
      "Number of examples= 439\n",
      "Number of inputs= 10\n",
      "Calculating answers for test data...\n",
      "Saving classifications for test data...\n",
      "Checking test error...\n",
      "Test errors= 3  ->  0.00683371298405467 %\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "class PerceptronOnline:\n",
    "    \"\"\"\n",
    "    This is a perceptron which can process one example at a time.\n",
    "    Assumption: class label is given as {-1, 1}\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Perceptron constructor\"\"\"\n",
    "        self.num_of_inputs = num_of_inputs\n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2 * np.random.rand(self.num_of_inputs,)\n",
    "        self.w0 = -1 + 2 * np.random.rand()\n",
    "    def Forward(self, x): \n",
    "        \"\"\"Forward pass - calculate the output as {-1, 1} of the neuron for one example x\"\"\"\n",
    "        y = np.dot(self.w, x) + self.w0\n",
    "        return 1 if y > 0 else -1\n",
    "    def Update(self, x, d, eta):\n",
    "        \"\"\"Calculate the output for x (one example), compare with d and update the weights if necessary\"\"\"\n",
    "        if self.Forward(x) != d:\n",
    "            self.w += eta * x * d\n",
    "            self.w0 += eta * 1 * d\n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs or until the classification error is 0\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of correct class labels for examples in rows of X\n",
    "        The update to the weights vector is done after processing each example\n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            if self.CalculateErrors(X, D) == 0:\n",
    "                break\n",
    "            for j in range(len(X)):\n",
    "                self.Update(X[j], D[j], eta)\n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"Calculates the number of errors - missclassifications\"\"\"\n",
    "        self.errors = 0\n",
    "        for i in range(len(X)):\n",
    "            if self.Forward(X[i]) != D[i]:\n",
    "                self.errors += 1\n",
    "        return self.errors\n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "##############################################################################\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = PerceptronOnline(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 100\n",
    "eta = 0.01\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = []\n",
    "for x in test_data:\n",
    "    test_ans.append ( perc.Forward(x) )\n",
    "test_ans = np.array(test_ans)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_perconline.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 2 - Batch version of Perceptron learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "`\n",
    "Loading train data...\n",
    "Train data:\n",
    "Number of examples= 500\n",
    "Number of inputs= 10\n",
    "Initial number of errors= 271\n",
    "Training...\n",
    "End of training\n",
    "Errors for train data after training= 0\n",
    "Loading test data...\n",
    "Test data:\n",
    "Number of examples= 439\n",
    "Number of inputs= 10\n",
    "Calculating answers for test data...\n",
    "Saving classifications for test data...\n",
    "Checking test error...\n",
    "Test errors= 0  ->  0.0 %\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 135\n",
      "Training...\n",
      "End of training\n",
      "Errors for train data after training= 0\n",
      "Loading test data...\n",
      "Test data:\n",
      "Number of examples= 439\n",
      "Number of inputs= 10\n",
      "Calculating answers for test data...\n",
      "Saving classifications for test data...\n",
      "Checking test error...\n",
      "Test errors= 0  ->  0.0 %\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "class PerceptronBatch:\n",
    "    \"\"\"\n",
    "    This is a perceptron which can process all examples at a time.\n",
    "    Assumption: class label is given as {-1, 1}\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Perceptron constructor\"\"\"\n",
    "        self.num_of_inputs = num_of_inputs\n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2 * np.random.rand(self.num_of_inputs,)\n",
    "        self.w0 = -1 + 2 * np.random.rand()\n",
    "    def Forward(self, X): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as a vector of {-1, 1} of the neuron for all examples in X\n",
    "        X: matrix with examples as rows\n",
    "        \"\"\"\n",
    "        Y = np.dot(X, self.w) + self.w0\n",
    "        return np.array([1 if y > 0 else -1 for y in Y])\n",
    "    def Update(self, X, D, eta):\n",
    "        \"\"\"Calculate the output for all examples in X (as rows), compare with D and update the weights if necessary\"\"\"\n",
    "        Y = self.Forward(X)\n",
    "        diff = Y!=D\n",
    "        updateW = np.array([X[i]*D[i] for i in range(len(Y)) if Y[i] != D[i]]).sum()\n",
    "        updateW0 = np.array([D[i] for i in range(len(Y)) if Y[i] != D[i]]).sum()\n",
    "        self.w += eta * (X[diff] * D[diff, None]).sum(axis=0)\n",
    "        self.w0 += eta * (D[diff, None]).sum()\n",
    "\n",
    "\n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs or until the classification error is 0\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of correct class labels for examples in rows of X\n",
    "        The update to the weights vector is done once per epoch, based on all examples\n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            if self.CalculateErrors(X, D) == 0:\n",
    "                break\n",
    "            self.Update(X, D, eta)\n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"Calculates the number of errors - missclassifications\"\"\"\n",
    "        Y = self.Forward(X)\n",
    "        self.errors = len([Y[i] for i in range(len(Y)) if Y[i] != D[i]])\n",
    "        return self.errors\n",
    "    \n",
    "\n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "##############################################################################\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = PerceptronBatch(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 100\n",
    "eta = 0.01\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = perc.Forward(test_data)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_percbatch.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Online version of Widrow-Hoff learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "---CLASSIFICATION PROBLEM---\n",
    "\n",
    "Loading train data...\n",
    "\n",
    "Train data:\n",
    "\n",
    "Number of examples= 500\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Initial number of errors= 241\n",
    "\n",
    "Initial MSE= 1.5702372419231343\n",
    "\n",
    "Training...\n",
    "\n",
    "End of training\n",
    "\n",
    "Errors for train data after training= 6\n",
    "\n",
    "MSE for train data after training= 0.31192984053640277\n",
    "\n",
    "Loading test data...\n",
    "\n",
    "Test data:\n",
    "\n",
    "Number of examples= 439\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Calculating answers for test data...\n",
    "\n",
    "Saving classifications for test data...\n",
    "\n",
    "Checking test error...\n",
    "\n",
    "Test errors= 6  ->  0.01366742596810934 %\n",
    "\n",
    "\n",
    "---REGRESSION PROBLEM---\n",
    "\n",
    "x= [-6.  -5.5 -5.  -4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5\n",
    "  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5]\n",
    "\n",
    "Initial MSE= 7.177903123126157\n",
    "\n",
    "Training for regression...\n",
    "\n",
    "After training, training MSE= 0.04428786345738948\n",
    "\n",
    "After training, testing MSE= 0.005203074366538246\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CLASSIFICATION PROBLEM---\n",
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 314\n",
      "Initial MSE= 2.7987076205195285\n",
      "Training...\n",
      "End of training\n",
      "Errors for train data after training= 0\n",
      "MSE for train data after training= 0.5760313207387546\n",
      "Loading test data...\n",
      "Test data:\n",
      "Number of examples= 439\n",
      "Number of inputs= 10\n",
      "Calculating answers for test data...\n",
      "Saving classifications for test data...\n",
      "Checking test error...\n",
      "Test errors= 1  ->  0.002277904328018223 %\n",
      "\n",
      "---REGRESSION PROBLEM---\n",
      "x= [-6.  -5.5 -5.  -4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5\n",
      "  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5]\n",
      "Initial MSE= 3.6103582809537795\n",
      "Training for regression...\n",
      "After training, training MSE= 0.047172555445742004\n",
      "After training, testing MSE= 0.0034666268807926753\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "class WidrowHoffOnline:\n",
    "    \"\"\"\n",
    "    This is a Widrow-Hoff model which can process one example at a time.\n",
    "    Can be used for both classification and regression problems\n",
    "    Assumption: class label is given as {-1, 1} in classification problems\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.num_of_inputs = num_of_inputs\n",
    "        self.w = None\n",
    "        self.InitWeights()\n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2 * np.random.rand(self.num_of_inputs + 1,)\n",
    "    def Forward(self, x): \n",
    "        \"\"\"Forward pass - calculate the output as a real value of the neuron for one example x\"\"\"\n",
    "        y = np.dot(self.w[1:].T, x) + self.w[0]\n",
    "        return y\n",
    "    def ForwardClassify(self, x): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as {-1, 1} by comparing the real output value of the neuron with threshold 0; \n",
    "        for one example x\n",
    "        \"\"\"\n",
    "        return 1 if self.Forward(x) > 0 else -1\n",
    "    def Update(self, x, d, eta):\n",
    "        \"\"\"Calculate the output for x (one example), and update the weights\"\"\"\n",
    "        if self.ForwardClassify(x) != d:\n",
    "            y = self.Forward(x)\n",
    "            self.w[1:] += eta * np.dot(d - y, x)\n",
    "            self.w[0] += eta * (d - y)\n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of real values required for examples in rows of X \n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            if self.CalculateErrors(X, D) == 0:\n",
    "                break\n",
    "            for j in range(len(X)):\n",
    "                self.Update(X[j], D[j], eta)\n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the number of errors - missclassifications;\n",
    "        D - assumed to be {-1, 1} here\n",
    "        \"\"\"\n",
    "        self.errors = 0\n",
    "        for i in range(len(X)):\n",
    "            if self.ForwardClassify(X[i]) != D[i]:\n",
    "                self.errors += 1\n",
    "        return self.errors\n",
    "    def CalculateMSE(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the mean square error \n",
    "        D - assumed to be a vector of any real values here\n",
    "        \"\"\"\n",
    "        return ( ((np.dot(X, self.w[1:]) + self.w[0]) - D) * ((np.dot(X, self.w[1:]) + self.w[0]) - D) ).sum() / len(X)\n",
    "        \n",
    "    \n",
    "\n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "############################################################################## \n",
    "print('---CLASSIFICATION PROBLEM---')\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = WidrowHoffOnline(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "start_mse = perc.CalculateMSE(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "print('Initial MSE=',start_mse)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 200\n",
    "eta = 0.001\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "train_mse = perc.CalculateMSE(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "print('MSE for train data after training=',train_mse)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = []\n",
    "for x in test_data:\n",
    "    test_ans.append ( perc.ForwardClassify(x) )\n",
    "test_ans = np.array(test_ans)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_whonline.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')\n",
    "\n",
    "\n",
    "print()\n",
    "print('---REGRESSION PROBLEM---')\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "x = np.arange(xmin, xmax, 0.5)\n",
    "print ('x=',x)\n",
    "\n",
    "#real values of unknown process\n",
    "a = 0.6\n",
    "b = -0.4\n",
    "d = a*x + b\n",
    "\n",
    "#training data with noise (e.g., measurement errors)\n",
    "sigma = 0.2\n",
    "tr_d = d + np.random.randn(len(d)) * sigma\n",
    "\n",
    "x.shape = (x.shape[0], 1)\n",
    "\n",
    "perc_reg = WidrowHoffOnline(1)\n",
    "start_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('Initial MSE=', start_mse)\n",
    "\n",
    "print('Training for regression...')\n",
    "eta = 0.01\n",
    "max_epochs = 100\n",
    "perc_reg.Train(x, tr_d, eta, max_epochs)\n",
    "\n",
    "train_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('After training, training MSE=', train_mse)\n",
    "\n",
    "#test data \n",
    "x_test = np.arange(xmin, xmax, 0.3)\n",
    "d_test = a*x_test + b\n",
    "x_test.shape = (x_test.shape[0],1)\n",
    "\n",
    "test_mse = perc_reg.CalculateMSE(x_test, d_test)\n",
    "print('After training, testing MSE=', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Batch version of Widrow-Hoff learning\n",
    "\n",
    "Expected test output:\n",
    "\n",
    "---CLASSIFICATION PROBLEM---\n",
    "\n",
    "Loading train data...\n",
    "\n",
    "Train data:\n",
    "\n",
    "Number of examples= 500\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Initial number of errors= 320\n",
    "\n",
    "Initial MSE= 3.519674085434046\n",
    "\n",
    "Training...\n",
    "\n",
    "End of training\n",
    "\n",
    "Errors for train data after training= 6\n",
    "\n",
    "MSE for train data after training= 0.3119085202726676\n",
    "\n",
    "Loading test data...\n",
    "\n",
    "Test data:\n",
    "\n",
    "Number of examples= 439\n",
    "\n",
    "Number of inputs= 10\n",
    "\n",
    "Calculating answers for test data...\n",
    "\n",
    "Saving classifications for test data...\n",
    "\n",
    "Checking test error...\n",
    "\n",
    "Test errors= 6  ->  0.01366742596810934 %\n",
    "\n",
    "\n",
    "---REGRESSION PROBLEM---\n",
    "\n",
    "Initial MSE= 13.232938807228429\n",
    "\n",
    "Training for regression...\n",
    "\n",
    "After training, training MSE= 0.033557507870294406\n",
    "\n",
    "After training, testing MSE= 0.0035392872344154926\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CLASSIFICATION PROBLEM---\n",
      "Loading train data...\n",
      "Train data:\n",
      "Number of examples= 500\n",
      "Number of inputs= 10\n",
      "Initial number of errors= 231\n",
      "Initial MSE= 2.2395339981230276\n",
      "Training...\n",
      "End of training\n",
      "Errors for train data after training= 6\n",
      "MSE for train data after training= 0.31190852027264626\n",
      "Loading test data...\n",
      "Test data:\n",
      "Number of examples= 439\n",
      "Number of inputs= 10\n",
      "Calculating answers for test data...\n",
      "Saving classifications for test data...\n",
      "Checking test error...\n",
      "Test errors= 6  ->  0.01366742596810934 %\n",
      "\n",
      "---REGRESSION PROBLEM---\n",
      "Initial MSE= 1.674961142022056\n",
      "Training for regression...\n",
      "After training, training MSE= 0.03416996837872727\n",
      "After training, testing MSE= 0.0060950981653848215\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "class WidrowHoffBatch:\n",
    "    \"\"\"\n",
    "    This is a WidrowHoff model which can process all examples at a time.\n",
    "    Can be used for both classification and regression problems\n",
    "    Assumption: class label is given as {-1, 1} in classification problems\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_inputs):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.num_of_inputs = num_of_inputs\n",
    "        self.InitWeights()\n",
    "    def InitWeights(self):\n",
    "        \"\"\"Initializes weights to random values\"\"\"\n",
    "        self.w = -1 + 2 * np.random.rand(self.num_of_inputs + 1,)\n",
    "    def Forward(self, X): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as a vector of real values of the neuron for all examples in X\n",
    "        X: matrix with examples as rows\n",
    "        \"\"\"\n",
    "        Y = np.dot(X, self.w[1:].T) + self.w[0]\n",
    "        return Y\n",
    "    def ForwardClassify(self, X): \n",
    "        \"\"\"\n",
    "        Forward pass - calculate the output as a vector of {-1, 1} by comparing the real output values of the neuron with threshold 0; \n",
    "        X: matrix with examples as rows\n",
    "        \"\"\"\n",
    "        Y = self.Forward(X)\n",
    "        Y[Y>0] = 1\n",
    "        Y[Y<=0] = -1\n",
    "        return Y \n",
    "    def Update(self, X, D, eta):\n",
    "        \"\"\"Calculate the output for all examples in X (as rows), and update the weights \"\"\"\n",
    "        #self.w[1:] = np.dot(np.dot( np.linalg.inv( np.dot(X.T, X) ), X.T), D)\n",
    "        Y = self.Forward(X)\n",
    "        self.w[1:] += eta * np.dot(X.T, (D - Y))\n",
    "        self.w[0] += eta * np.dot(np.ones((1, X.shape[0])), (D-Y))\n",
    "    def Train(self, X, D, eta, epochs):\n",
    "        \"\"\"\n",
    "        Train for the maximum number of epochs\n",
    "        X: matrix with examples, each examples as a row\n",
    "        D: vector of real values required for examples in rows of X \n",
    "        \"\"\"\n",
    "        for i in range(epochs):\n",
    "            if self.CalculateErrors(X, D) == 0:\n",
    "                break\n",
    "            \n",
    "            self.Update(X, D, eta)\n",
    "    def CalculateErrors(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the number of errors - missclassifications\n",
    "        D - assumed to be {-1, 1} here\n",
    "        \"\"\"\n",
    "        classification = self.ForwardClassify(X)\n",
    "        self.errors = (classification!=D).sum()\n",
    "        return self.errors\n",
    "    def CalculateMSE(self, X, D):\n",
    "        \"\"\"\n",
    "        Calculates the mean square error \n",
    "        D - assumed to be a vector of any real values here\n",
    "        \"\"\"\n",
    "        return ( ((np.dot(X, self.w[1:]) + self.w[0]) - D) * ((np.dot(X, self.w[1:]) + self.w[0]) - D) ).sum() / len(X)\n",
    "    \n",
    "\n",
    "    \n",
    "##############################################################################\n",
    "#DO NOT CHANGE THE FOLLOWING CODE\n",
    "##############################################################################     \n",
    "print('---CLASSIFICATION PROBLEM---')\n",
    "print('Loading train data...')\n",
    "train_data = np.loadtxt('train10D.csv')\n",
    "X = train_data[:,:-1]\n",
    "D = train_data[:,-1]\n",
    "num_of_inputs = X.shape[1]\n",
    "print('Train data:')\n",
    "print('Number of examples=',X.shape[0])\n",
    "print('Number of inputs=',num_of_inputs)\n",
    "\n",
    "perc = WidrowHoffBatch(num_of_inputs)\n",
    "perc.InitWeights()\n",
    "\n",
    "start_errors = perc.CalculateErrors(X,D)\n",
    "start_mse = perc.CalculateMSE(X,D)\n",
    "print('Initial number of errors=',start_errors)\n",
    "print('Initial MSE=',start_mse)\n",
    "\n",
    "print('Training...')\n",
    "max_epochs = 100\n",
    "eta = 0.001\n",
    "perc.Train(X, D, eta, max_epochs)\n",
    "print('End of training')\n",
    "\n",
    "train_errors = perc.CalculateErrors(X,D)\n",
    "train_mse = perc.CalculateMSE(X,D)\n",
    "print('Errors for train data after training=',train_errors)\n",
    "print('MSE for train data after training=',train_mse)\n",
    "\n",
    "print('Loading test data...')\n",
    "test_data = np.loadtxt('test10D.csv')\n",
    "print('Test data:')\n",
    "print('Number of examples=',test_data.shape[0])\n",
    "print('Number of inputs=',test_data.shape[1])\n",
    "\n",
    "print('Calculating answers for test data...')\n",
    "test_ans = perc.ForwardClassify(test_data)\n",
    "print('Saving classifications for test data...')\n",
    "np.savetxt('test_data_classifications_whbatch.csv', test_ans)\n",
    "\n",
    "print('Checking test error...')\n",
    "true_test_labels = np.loadtxt('test10D_correct_ans.csv')\n",
    "test_errors = (true_test_labels != test_ans).sum()\n",
    "print('Test errors=',test_errors,' -> ',test_errors/float(test_data.shape[0]),'%')\n",
    "\n",
    "print()\n",
    "print('---REGRESSION PROBLEM---')\n",
    "xmin = -6\n",
    "xmax = 6\n",
    "x = np.arange(xmin, xmax, 0.5)\n",
    "\n",
    "#real values of unknown process\n",
    "a = 0.6\n",
    "b = -0.4\n",
    "d = a*x + b\n",
    "\n",
    "#training data with noise (e.g., measurement errors)\n",
    "sigma = 0.2\n",
    "tr_d = d + np.random.randn(len(d)) * sigma\n",
    "\n",
    "x.shape = (x.shape[0], 1)\n",
    "\n",
    "perc_reg = WidrowHoffBatch(1)\n",
    "start_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('Initial MSE=', start_mse)\n",
    "\n",
    "print('Training for regression...')\n",
    "eta = 0.001\n",
    "max_epochs = 100\n",
    "perc_reg.Train(x, tr_d, eta, max_epochs)\n",
    "\n",
    "train_mse = perc_reg.CalculateMSE(x, tr_d)\n",
    "print('After training, training MSE=', train_mse)\n",
    "\n",
    "#test data \n",
    "x_test = np.arange(xmin, xmax, 0.3)\n",
    "d_test = a*x_test + b\n",
    "x_test.shape = (x_test.shape[0],1)\n",
    "\n",
    "test_mse = perc_reg.CalculateMSE(x_test, d_test)\n",
    "print('After training, testing MSE=', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
